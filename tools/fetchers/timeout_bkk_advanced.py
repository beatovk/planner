from __future__ import annotations
from typing import Dict, List, Optional
import time
import re
import random
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from .base import normalize_event, parse_date_range

ROOT = "https://www.timeout.com/bangkok"

class TimeOutAdvancedFetcher:
    def __init__(self):
        self.session = requests.Session()
        self.user_agents = [
            # Desktop Chrome
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            
            # Desktop Firefox
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0",
            
            # Mobile Safari
            "Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (iPad; CPU OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1",
            
            # Mobile Chrome
            "Mozilla/5.0 (Linux; Android 14; Pixel 8) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36"
        ]
        
    def get_headers(self, referer=None):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏"""
        ua = random.choice(self.user_agents)
        is_mobile = "Mobile" in ua or "iPhone" in ua or "iPad" in ua
        
        headers = {
            "User-Agent": ua,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Language": "en-US,en;q=0.9,th;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none" if not referer else "same-origin",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0"
        }
        
        if referer:
            headers["Referer"] = referer
            
        if is_mobile:
            headers["Sec-CH-UA-Mobile"] = "?1"
            headers["Viewport-Width"] = "390"
        else:
            headers["Sec-CH-UA-Mobile"] = "?0"
            headers["Sec-CH-UA"] = '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"'
            headers["Sec-CH-UA-Platform"] = '"Windows"'
            
        return headers
    
    def smart_delay(self):
        """–ß–µ–ª–æ–≤–µ–∫–æ-–ø–æ–¥–æ–±–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏"""
        delay = random.uniform(3, 8)  # 3-8 —Å–µ–∫—É–Ω–¥
        print(f"    ‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ {delay:.1f}—Å...")
        time.sleep(delay)
    
    def get_html(self, url: str, method=1) -> Optional[BeautifulSoup]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç HTML —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏:
        method 1: –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ä–æ—Ç–∞—Ü–∏–µ–π UA
        method 2: –° –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –∑–∞—Ö–æ–¥–æ–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é
        method 3: Mobile UA
        method 4: –° cookies –æ—Ç –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        print(f"    üåê –ú–µ—Ç–æ–¥ {method}: {url}")
        
        try:
            if method == 2:
                # –°–Ω–∞—á–∞–ª–∞ –∑–∞—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è cookies
                main_headers = self.get_headers()
                main_resp = self.session.get(ROOT, headers=main_headers, timeout=15)
                print(f"    üè† –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {main_resp.status_code}")
                time.sleep(random.uniform(2, 4))
                
            if method == 3:
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º mobile UA
                mobile_ua = "Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1"
                headers = self.get_headers(ROOT)
                headers["User-Agent"] = mobile_ua
            else:
                headers = self.get_headers(ROOT if method > 1 else None)
            
            self.smart_delay()
            
            resp = self.session.get(url, headers=headers, timeout=20)
            print(f"    üìä –û—Ç–≤–µ—Ç: {resp.status_code} ({len(resp.text)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            if resp.status_code == 200:
                return BeautifulSoup(resp.text, "lxml")
            elif resp.status_code in [403, 429]:
                print(f"    üö´ –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ {resp.status_code}")
                return None
            else:
                print(f"    ‚ùå HTTP {resp.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            print(f"    ‚è∞ Timeout")
            return None
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
            return None
    
    def try_all_methods(self, url: str) -> Optional[BeautifulSoup]:
        """–ü—Ä–æ–±—É–µ—Ç –≤—Å–µ –º–µ—Ç–æ–¥—ã –ø–æ –æ—á–µ—Ä–µ–¥–∏"""
        for method in range(1, 5):
            soup = self.get_html(url, method)
            if soup:
                print(f"    ‚úÖ –ú–µ—Ç–æ–¥ {method} —Å—Ä–∞–±–æ—Ç–∞–ª!")
                return soup
            print(f"    ‚ùå –ú–µ—Ç–æ–¥ {method} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª")
        
        print(f"    üíÄ –í—Å–µ –º–µ—Ç–æ–¥—ã failed –¥–ª—è {url}")
        return None

def is_fresh_event(date_str: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ —Å–æ–±—ã—Ç–∏–µ –≤ –±–ª–∏–∂–∞–π—à–∏–µ 2 –Ω–µ–¥–µ–ª–∏"""
    if not date_str:
        return False
        
    try:
        event_date = datetime.strptime(date_str, "%Y-%m-%d")
        today = datetime.now()
        two_weeks_later = today + timedelta(weeks=2)
        
        # –°–æ–±—ã—Ç–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –±—É–¥—É—â–µ–º, –Ω–æ –Ω–µ –±–æ–ª–µ–µ —á–µ–º —á–µ—Ä–µ–∑ 2 –Ω–µ–¥–µ–ª–∏
        return today <= event_date <= two_weeks_later
    except:
        return False

def fetch(cat_id: str = None) -> List[Dict]:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ñ–µ—Ç—á–µ—Ä –¥–ª—è Time Out Bangkok
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
    """
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π Time Out Bangkok —Ñ–µ—Ç—á–µ—Ä...")
    start_time = time.time()
    
    fetcher = TimeOutAdvancedFetcher()
    out = []
    
    # –†–∞–∑–Ω—ã–µ URL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    if cat_id == "food":
        urls = [f"{ROOT}/food-and-drink"]
    elif cat_id in ["live_music_gigs", "electronic_music"]:
        urls = [f"{ROOT}/music-and-nightlife"]
    elif cat_id == "art_galleries":
        urls = [f"{ROOT}/art-and-culture"]
    else:
        urls = [
            f"{ROOT}/things-to-do",
            f"{ROOT}/whats-on",
            f"{ROOT}/events"
        ]
    
    for url_idx, url in enumerate(urls):
        if len(out) >= 5:  # –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            break
            
        print(f"\nüìã –°—Ç—Ä–∞–Ω–∏—Ü–∞ {url_idx + 1}/{len(urls)}: {url}")
        
        soup = fetcher.try_all_methods(url)
        if not soup:
            continue
            
        # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Å–æ–±—ã—Ç–∏–π —Å —Ä–∞–∑–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏
        selectors = [
            "article",
            ".card",
            ".listing", 
            ".event-card",
            ".item",
            "[data-testid*='card']",
            ".article-card",
            ".content-card"
        ]
        
        cards = []
        for selector in selectors:
            found = soup.select(selector)
            if found:
                cards = found
                print(f"    üéØ –ù–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º '{selector}'")
                break
        
        if not cards:
            print(f"    ‚ùå –ö–∞—Ä—Ç–æ—á–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            continue
            
        events_from_page = 0
        for card_idx, card in enumerate(cards[:10]):  # –º–∞–∫—Å–∏–º—É–º 10 —Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if events_from_page >= 3 or len(out) >= 5:
                break
                
            try:
                print(f"    üé´ –ö–∞—Ä—Ç–æ—á–∫–∞ {card_idx + 1}/{min(len(cards), 10)}")
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                title_selectors = ["h1", "h2", "h3", "h4", ".title", ".headline", "[data-testid*='title']"]
                title = None
                for sel in title_selectors:
                    title_el = card.select_one(sel)
                    if title_el:
                        title = title_el.get_text(strip=True)
                        if title and len(title) >= 10:
                            break
                        title = None
                
                if not title:
                    print(f"      ‚ùå –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    continue
                
                print(f"      üìù –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
                
                # –°—Å—ã–ª–∫–∞
                link_el = card.select_one("a")
                if not link_el:
                    print(f"      ‚ùå –°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                    continue
                    
                event_url = link_el.get("href", "")
                if not event_url:
                    print(f"      ‚ùå –ü—É—Å—Ç–∞—è —Å—Å—ã–ª–∫–∞")
                    continue
                    
                if event_url.startswith("/"):
                    event_url = "https://www.timeout.com" + event_url
                elif not event_url.startswith("http"):
                    print(f"      ‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω–∞—è —Å—Å—ã–ª–∫–∞: {event_url}")
                    continue
                
                # –î–∞—Ç–∞ - –∏—â–µ–º –≤–µ–∑–¥–µ
                date_str = None
                date_selectors = [".date", ".time", "time", "[data-testid*='date']", "[data-testid*='time']"]
                
                for sel in date_selectors:
                    date_el = card.select_one(sel)
                    if date_el:
                        date_text = date_el.get_text(strip=True)
                        if date_text:
                            start_date, end_date = parse_date_range(date_text)
                            if start_date:
                                date_str = start_date
                                break
                
                # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–æ–¥–Ω—è + 1 –¥–µ–Ω—å (–¥–ª—è —Å–≤–µ–∂–∏—Ö –ø–æ–¥–±–æ—Ä–æ–∫)
                if not date_str:
                    date_str = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–µ–∂–µ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è
                if not is_fresh_event(date_str):
                    print(f"      üóìÔ∏è –°–æ–±—ã—Ç–∏–µ –Ω–µ —Å–≤–µ–∂–µ–µ: {date_str}")
                    continue
                
                print(f"      üìÖ –î–∞—Ç–∞: {date_str}")
                
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                image = None
                img_el = card.select_one("img")
                if img_el:
                    image = img_el.get("src") or img_el.get("data-src") or img_el.get("data-lazy-src")
                    if image and image.startswith("/"):
                        image = "https://media.timeout.com" + image
                
                # –û–ø–∏—Å–∞–Ω–∏–µ
                desc_el = card.select_one("p, .description, .summary, .excerpt")
                desc = desc_el.get_text(strip=True)[:300] if desc_el else None
                
                # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
                category_hint = cat_id or "events"
                if "music" in url or "nightlife" in url:
                    category_hint = "live_music_gigs"
                elif "art" in url or "culture" in url:
                    category_hint = "art_galleries"
                elif "food" in url:
                    category_hint = "food"
                
                # –¢–µ–≥–∏
                tags = ["TimeOut Picks", "Fresh"]
                
                event = normalize_event(
                    title=title,
                    date_iso=date_str,
                    url=event_url,
                    source="timeout.com/bangkok",
                    category_hint=category_hint,
                    desc=desc,
                    image=image,
                    venue="Bangkok",
                    tags=tags
                )
                
                out.append(event)
                events_from_page += 1
                print(f"      ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–±—ã—Ç–∏–µ!")
                
            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                continue
        
        print(f"    üìä –ù–∞–π–¥–µ–Ω–æ {events_from_page} —Å–æ–±—ã—Ç–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
        
        # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
        if url_idx < len(urls) - 1:
            fetcher.smart_delay()
    
    elapsed = time.time() - start_time
    print(f"\nüéâ Time Out —Ñ–µ—Ç—á–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω: {len(out)} —Å–≤–µ–∂–∏—Ö —Å–æ–±—ã—Ç–∏–π –∑–∞ {elapsed:.1f}—Å")
    
    return out[:5]
