#!/usr/bin/env python3
"""
Time Out Bangkok Places Scraper
Extracts individual places with titles, images, and descriptions from Time Out Bangkok
"""

import sys
import time
import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ Python path
sys.path.insert(0, str(Path('.') / 'src'))

from integration import create_places_pipeline
from cache import CacheConfig


def get_timeout_html(url: str, timeout: int = 15):
    """
    –ü–æ–ª—É—á–∞–µ—Ç HTML —Å Time Out Bangkok
    """
    import requests
    from bs4 import BeautifulSoup
    import random
    
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ]
    
    headers = {
        "User-Agent": random.choice(user_agents),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Cache-Control": "max-age=0"
    }
    
    try:
        session = requests.Session()
        session.headers.update(headers)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(random.uniform(1, 3))
        
        response = session.get(url, timeout=timeout)
        if response.status_code != 200:
            print(f"HTTP {response.status_code} for {url}")
            return None
        
        return BeautifulSoup(response.text, "html.parser")
        
    except Exception as e:
        print(f"Error fetching {url}: {e}")
        return None


def extract_places_from_best_things_page(url: str) -> List[Dict[str, Any]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã "Best Things to Do in Bangkok"
    """
    places = []
    
    try:
        print(f"üìÑ Fetching: {url}")
        soup = get_timeout_html(url)
        if not soup:
            print(f"  ‚ùå Failed to get HTML")
            return places
        
        # –ò—â–µ–º –≤—Å–µ –º–µ—Å—Ç–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        # –ö–∞–∂–¥–æ–µ –º–µ—Å—Ç–æ –æ–±—ã—á–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ
        place_blocks = find_place_blocks(soup)
        print(f"  üìä Found {len(place_blocks)} place blocks")
        
        for i, block in enumerate(place_blocks):
            try:
                place = extract_place_from_block(block, i+1)
                if place:
                    places.append(place)
                    print(f"    ‚úì Extracted: {place['title'][:40]}...")
                    
            except Exception as e:
                print(f"    ‚ö†Ô∏è Error extracting place {i+1}: {e}")
                continue
        
        print(f"  ‚úÖ Successfully extracted {len(places)} places")
        return places
        
    except Exception as e:
        print(f"  ‚ùå Error processing page: {e}")
        return places


def find_place_blocks(soup):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –±–ª–æ–∫–∏ —Å –º–µ—Å—Ç–∞–º–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    """
    place_blocks = []
    
    # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –≥–¥–µ –º–æ–≥—É—Ç –±—ã—Ç—å –º–µ—Å—Ç–∞
    
    # 1. –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ h2, h3, h4 (–æ–±—ã—á–Ω–æ —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç)
    headings = soup.find_all(['h2', 'h3', 'h4'])
    
    for heading in headings:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        heading_text = heading.get_text(strip=True)
        if any(skip in heading_text.lower() for skip in [
            'the best things to do in bangkok', 'advertising', 'popular on time out',
            'you may also like', 'discover time out', 'about us', 'contact us'
        ]):
            continue
        
        # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞
        if len(heading_text) > 5 and len(heading_text) < 100:
            # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –±–ª–æ–∫ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
            block = find_content_block_for_heading(heading)
            if block:
                place_blocks.append(block)
    
    # 2. –ò—â–µ–º –±–ª–æ–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
    images = soup.find_all('img')
    for img in images:
        alt = img.get('alt', '')
        if alt and len(alt) > 10:
            # –ò—â–µ–º –±–ª–æ–∫ —Å —ç—Ç–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
            block = find_content_block_for_image(img)
            if block and block not in place_blocks:
                place_blocks.append(block)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_blocks = []
    seen_content = set()
    
    for block in place_blocks:
        content_hash = hash(str(block))
        if content_hash not in seen_content:
            unique_blocks.append(block)
            seen_content.add(content_hash)
    
    return unique_blocks


def find_content_block_for_heading(heading):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –±–ª–æ–∫ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
    """
    try:
        # –ò—â–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        parent = heading.parent
        
        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä—è–¥–æ–º
        nearby_image = find_nearby_image(heading)
        
        # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        description = find_nearby_description(heading)
        
        # –°–æ–∑–¥–∞–µ–º –±–ª–æ–∫ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        block = {
            'heading': heading,
            'image': nearby_image,
            'description': description,
            'parent': parent
        }
        
        return block
        
    except Exception:
        return None


def find_content_block_for_image(img):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –±–ª–æ–∫ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    try:
        # –ò—â–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        parent = img.parent
        
        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä—è–¥–æ–º
        nearby_heading = find_nearby_heading(img)
        
        # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        description = find_nearby_description(img)
        
        # –°–æ–∑–¥–∞–µ–º –±–ª–æ–∫ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        block = {
            'heading': nearby_heading,
            'image': img,
            'description': description,
            'parent': parent
        }
        
        return block
        
    except Exception:
        return None


def find_nearby_image(element, max_distance: int = 5):
    """
    –ò—â–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä—è–¥–æ–º —Å —ç–ª–µ–º–µ–Ω—Ç–æ–º
    """
    try:
        # –ò—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
        parent = element.parent
        if parent:
            img = parent.find('img')
            if img:
                return img
            
            # –ò—â–µ–º –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            siblings = parent.find_next_siblings()
            for sibling in siblings[:max_distance]:
                img = sibling.find('img')
                if img:
                    return img
        
        return None
        
    except Exception:
        return None


def find_nearby_heading(element, max_distance: int = 5):
    """
    –ò—â–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä—è–¥–æ–º —Å —ç–ª–µ–º–µ–Ω—Ç–æ–º
    """
    try:
        # –ò—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
        parent = element.parent
        if parent:
            heading = parent.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
            if heading:
                return heading
            
            # –ò—â–µ–º –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            siblings = parent.find_next_siblings()
            for sibling in siblings[:max_distance]:
                heading = sibling.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                if heading:
                    return heading
        
        return None
        
    except Exception:
        return None


def find_nearby_description(element, max_distance: int = 5):
    """
    –ò—â–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ä—è–¥–æ–º —Å —ç–ª–µ–º–µ–Ω—Ç–æ–º
    """
    try:
        # –ò—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
        parent = element.parent
        if parent:
            # –ò—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
            paragraphs = parent.find_all('p')
            for p in paragraphs:
                text = p.get_text(strip=True)
                if text and len(text) > 20:
                    return p
            
            # –ò—â–µ–º –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            siblings = parent.find_next_siblings()
            for sibling in siblings[:max_distance]:
                paragraphs = sibling.find_all('p')
                for p in paragraphs:
                    text = p.get_text(strip=True)
                    if text and len(text) > 20:
                        return p
        
        return None
        
    except Exception:
        return None


def extract_place_from_block(block, place_num: int) -> Optional[Dict[str, Any]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Å—Ç–µ –∏–∑ –±–ª–æ–∫–∞
    """
    try:
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title = ""
        if block.get('heading'):
            title = block['heading'].get_text(strip=True)
        elif block.get('image'):
            alt = block['image'].get('alt', '')
            if alt and len(alt) > 5:
                title = alt
        
        if not title or len(title) < 5:
            return None
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_url = None
        if block.get('image'):
            src = block['image'].get('src', '')
            if src and src.startswith('http'):
                image_url = src
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        description = ""
        if block.get('description'):
            desc_text = block['description'].get_text(strip=True)
            if desc_text and len(desc_text) > 20:
                description = desc_text[:300]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º alt —Ç–µ–∫—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if not description and block.get('image'):
            alt = block['image'].get('alt', '')
            if alt and len(alt) > 10:
                description = alt
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–ª–∞–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
        flags = determine_flags_from_content(title, description)
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Å—Ç–æ
        place = {
            'title': title,
            'image': image_url,
            'description': description,
            'flags': flags,
            'source': 'timeout.com',
            'city': 'Bangkok',
            'place_number': place_num
        }
        
        return place
        
    except Exception as e:
        print(f"      ‚ö†Ô∏è Error extracting place: {e}")
        return None


def determine_flags_from_content(title: str, description: str) -> List[str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–ª–∞–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
    """
    flags = []
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    content = (title + " " + description).lower()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    if any(word in content for word in ['restaurant', 'food', 'dining', 'eat', 'cuisine']):
        flags.extend(['food_dining', 'restaurants'])
    elif any(word in content for word in ['bar', 'pub', 'nightlife', 'club', 'drink']):
        flags.extend(['nightlife', 'bars'])
    elif any(word in content for word in ['market', 'shopping', 'mall', 'shop']):
        flags.extend(['shopping', 'markets'])
    elif any(word in content for word in ['museum', 'gallery', 'art', 'exhibition']):
        flags.extend(['culture', 'art', 'museums'])
    elif any(word in content for word in ['park', 'garden', 'nature', 'forest']):
        flags.extend(['nature', 'parks', 'outdoors'])
    elif any(word in content for word in ['spa', 'wellness', 'yoga', 'fitness']):
        flags.extend(['wellness', 'health'])
    elif any(word in content for word in ['hotel', 'accommodation', 'resort']):
        flags.extend(['accommodation', 'hotels'])
    elif any(word in content for word in ['theater', 'cinema', 'concert', 'show', 'performance']):
        flags.extend(['entertainment', 'culture'])
    elif any(word in content for word in ['temple', 'wat', 'religious', 'buddhist']):
        flags.extend(['culture', 'religion', 'temples'])
    elif any(word in content for word in ['street', 'alley', 'soi', 'neighborhood']):
        flags.extend(['local', 'neighborhoods'])
    else:
        flags.append('attractions')
    
    return flags


def collect_timeout_bangkok_places() -> List[Dict[str, Any]]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã "Best Things to Do in Bangkok"
    """
    print("üöÄ Starting Time Out Bangkok Places Collection...")
    print("=" * 60)
    
    # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –º–µ—Å—Ç–∞–º–∏
    main_url = "https://www.timeout.com/bangkok/things-to-do/best-things-to-do-in-bangkok"
    
    print(f"üì° Collecting from: {main_url}")
    places = extract_places_from_best_things_page(main_url)
    
    if not places:
        print("‚ùå No places collected")
        return []
    
    print(f"üìä Collection Summary:")
    print(f"   Total places found: {len(places)}")
    
    return places


def convert_to_pipeline_format(places: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Å—Ç–∞ Time Out –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    pipeline_places = []
    
    for i, place in enumerate(places):
        try:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
            place_id = f"timeout_place_{i+1}_{int(time.time())}"
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ç–æ
            photos = []
            image_url = place.get('image')
            if image_url:
                photos.append({
                    'url': image_url,
                    'width': 1200,
                    'height': 800
                })
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞
            pipeline_place = {
                'id': place_id,
                'name': place.get('title', 'Unknown Place'),
                'city': 'Bangkok',
                'domain': 'timeout.com',
                'url': '',  # Time Out –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–µ—Å—Ç–∞
                'description': place.get('description', ''),
                'address': 'Bangkok, Thailand',
                'geo_lat': None,
                'geo_lng': None,
                'tags': [],
                'flags': place.get('flags', ['attractions']),
                'phone': None,
                'email': None,
                'website': None,
                'hours': None,
                'price_level': None,
                'rating': None,
                'photos': photos,
                'image_url': image_url,
                'quality_score': 0.85,
                'last_updated': datetime.now().strftime('%Y-%m-%d')
            }
            
            pipeline_places.append(pipeline_place)
            
        except Exception as e:
            print(f"     ‚ö†Ô∏è Error converting place {i}: {e}")
            continue
    
    print(f"     ‚úì Converted {len(pipeline_places)} places to pipeline format")
    return pipeline_places


def main():
    """Main function to collect and process Time Out Bangkok places."""
    try:
        # –°–±–æ—Ä –º–µ—Å—Ç
        places = collect_timeout_bangkok_places()
        
        if not places:
            print("‚ùå No places collected")
            return 1
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞
        print("\nüîÑ Converting places to pipeline format...")
        pipeline_places = convert_to_pipeline_format(places)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüíæ Saving collected places...")
        save_collected_places(places, pipeline_places)
        
        print("\n‚úÖ Time Out Bangkok collection completed!")
        print(f"üìä Total places collected: {len(places)}")
        print(f"üîÑ Places ready for pipeline: {len(pipeline_places)}")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå Error in collection: {e}")
        import traceback
        traceback.print_exc()
        return 1


def save_collected_places(places: List[Dict], pipeline_places: List[Dict]):
    """Save collected places to files."""
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_dir = Path('results')
        results_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        raw_file = results_dir / f'timeout_bangkok_places_raw_{timestamp}.json'
        with open(raw_file, 'w', encoding='utf-8') as f:
            json.dump(places, f, indent=2, ensure_ascii=False)
        print(f"     ‚úì Raw data saved to {raw_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        pipeline_file = results_dir / f'timeout_bangkok_places_pipeline_{timestamp}.json'
        with open(pipeline_file, 'w', encoding='utf-8') as f:
            json.dump(pipeline_places, f, indent=2, ensure_ascii=False)
        print(f"     ‚úì Pipeline data saved to {pipeline_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = results_dir / f'timeout_bangkok_places_report_{timestamp}.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("Time Out Bangkok Places Collection Report\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Collection Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total Places: {len(places)}\n")
            f.write(f"Pipeline Ready: {len(pipeline_places)}\n\n")
            
            f.write("Collected Places:\n")
            for i, place in enumerate(places, 1):
                f.write(f"\n{i}. {place.get('title', 'Unknown')}\n")
                f.write(f"   Flags: {', '.join(place.get('flags', []))}\n")
                if place.get('image'):
                    f.write(f"   Image: Yes\n")
                if place.get('description'):
                    f.write(f"   Description: {place.get('description', '')[:100]}...\n")
        
        print(f"     ‚úì Report saved to {report_file}")
        
    except Exception as e:
        print(f"     ‚ùå Error saving results: {e}")


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
