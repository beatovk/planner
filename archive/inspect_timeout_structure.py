#!/usr/bin/env python3
"""
Inspect Time Out Bangkok Structure
Look at the actual HTML structure to understand how to parse it
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º tools –≤ Python path
sys.path.insert(0, str(Path('.') / 'tools'))

from fetchers.base import get_html


def main():
    """Inspect the Time Out Bangkok HTML structure."""
    print("üîç Inspecting Time Out Bangkok Structure...")
    print("=" * 60)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç–∞—é—â–∏–µ URL
    working_urls = [
        "https://www.timeout.com/bangkok",
        "https://www.timeout.com/bangkok/things-to-do"
    ]
    
    for url in working_urls:
        print(f"üì° Inspecting: {url}")
        inspect_page_structure(url)
        print()


def inspect_page_structure(url):
    """Inspect the structure of a specific page."""
    try:
        soup = get_html(url)
        if not soup:
            print("   ‚ùå Failed to get HTML")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        title = soup.find('title')
        title_text = title.get_text() if title else "No title"
        print(f"   üìÑ Title: {title_text}")
        
        # –ò—â–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞—Ä—Ç–æ—á–µ–∫
        print("   üîç Looking for card selectors...")
        
        selectors_to_try = [
            ".card", ".event-card", ".listing-card", "article", ".article-card", 
            ".feature-card", ".post", ".item", ".listing", ".result",
            "[class*='card']", "[class*='article']", "[class*='post']",
            "[class*='listing']", "[class*='item']"
        ]
        
        for selector in selectors_to_try:
            try:
                elements = soup.select(selector)
                if elements:
                    print(f"     ‚úì {selector}: {len(elements)} elements")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                    if len(elements) > 0:
                        first_element = elements[0]
                        print(f"       First element structure:")
                        print(f"         Tag: {first_element.name}")
                        print(f"         Classes: {first_element.get('class', [])}")
                        
                        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        title_el = first_element.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                        if title_el:
                            title_text = title_el.get_text(strip=True)
                            print(f"         Title: {title_text[:50]}...")
                        
                        # –ò—â–µ–º —Å—Å—ã–ª–∫—É
                        link_el = first_element.find('a')
                        if link_el:
                            href = link_el.get('href', '')
                            print(f"         Link: {href[:50]}...")
                        
                        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                        img_el = first_element.find('img')
                        if img_el:
                            src = img_el.get('src', '')
                            print(f"         Image: {src[:50]}...")
                        
                        break
                        
                else:
                    print(f"     ‚ö†Ô∏è {selector}: No elements found")
                    
            except Exception as e:
                print(f"     ‚úó {selector}: Error - {e}")
        
        # –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        print("   üîç Looking for alternative structures...")
        
        # –ò—â–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        print(f"     Total headings: {len(headings)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        for i, heading in enumerate(headings[:5]):
            text = heading.get_text(strip=True)
            if text and len(text) > 5:
                print(f"       {i+1}. {text[:60]}...")
        
        # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏
        links = soup.find_all('a', href=True)
        print(f"     Total links: {len(links)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Å—ã–ª–æ–∫ —Å —Ç–µ–∫—Å—Ç–æ–º
        link_count = 0
        for link in links:
            text = link.get_text(strip=True)
            href = link.get('href', '')
            if text and len(text) > 5 and href.startswith('/'):
                print(f"       {link_count+1}. {text[:40]}... -> {href}")
                link_count += 1
                if link_count >= 5:
                    break
        
        # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images = soup.find_all('img')
        print(f"     Total images: {len(images)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for i, img in enumerate(images[:3]):
            src = img.get('src', '')
            alt = img.get('alt', '')
            if src:
                print(f"       {i+1}. {src[:50]}... (alt: {alt[:30]}...)")
        
    except Exception as e:
        print(f"   ‚ùå Error inspecting page: {e}")


if __name__ == "__main__":
    main()
